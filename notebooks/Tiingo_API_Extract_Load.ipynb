{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary modules\n",
    "import os\n",
    "import requests\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine, text\n",
    "from dotenv import load_dotenv\n",
    "import time\n",
    "from pymysql.err import IntegrityError, OperationalError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load environment variables from .env\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Establish a database connection using SQLAlchemy and credentials from the .env file\n",
    "DB_USER = os.getenv('DB_USER')\n",
    "DB_PASSWORD = os.getenv('DB_PASSWORD')\n",
    "DB_HOST = os.getenv('DB_HOST')\n",
    "DB_PORT = os.getenv('DB_PORT')\n",
    "DB_NAME = os.getenv('DB_NAME')\n",
    "\n",
    "if None in (DB_USER, DB_PASSWORD, DB_HOST, DB_PORT, DB_NAME):\n",
    "    raise Exception(\"Database credentials are not fully set in the .env file.\")\n",
    "\n",
    "engine = create_engine(f'mysql+pymysql://{DB_USER}:{DB_PASSWORD}@{DB_HOST}:{DB_PORT}/{DB_NAME}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Query tickers from raw_wikipedia_sp500 ---\n",
    "with engine.connect() as conn:\n",
    "    query_wiki = text(\"SELECT DISTINCT symbol FROM raw_wikipedia_sp500\")\n",
    "    df_wiki = pd.read_sql(query_wiki, conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize ticker symbols: strip any extra whitespace and convert to uppercase\n",
    "df_wiki['symbol'] = df_wiki['symbol'].str.strip().str.upper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Query tickers already in raw_prices ---\n",
    "with engine.connect() as conn:\n",
    "    query_prices = text(\"SELECT DISTINCT symbol FROM raw_prices\")\n",
    "    df_prices = pd.read_sql(query_prices, conn)\n",
    "\n",
    "if not df_prices.empty:\n",
    "    processed_tickers = set(df_prices['symbol'].str.strip().str.upper())\n",
    "else:\n",
    "    processed_tickers = set()\n",
    "\n",
    "all_tickers = set(df_wiki['symbol'])\n",
    "new_tickers = list(all_tickers - processed_tickers)\n",
    "new_tickers.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total tickers in Wikipedia table: 503\n",
      "Tickers already processed in raw_prices: 100\n",
      "New tickers to process in this batch: 50\n",
      "Tickers in current batch: ['CNP', 'COF', 'COO', 'COP', 'COR', 'COST', 'CPAY', 'CPB', 'CPRT', 'CPT', 'CRL', 'CRM', 'CRWD', 'CSCO', 'CSGP', 'CSX', 'CTAS', 'CTRA', 'CTSH', 'CTVA', 'CVS', 'CVX', 'CZR', 'D', 'DAL', 'DASH', 'DAY', 'DD', 'DE', 'DECK', 'DELL', 'DFS', 'DG', 'DGX', 'DHI', 'DHR', 'DIS', 'DLR', 'DLTR', 'DOC', 'DOV', 'DOW', 'DPZ', 'DRI', 'DTE', 'DUK', 'DVA', 'DVN', 'DXCM', 'EA']\n"
     ]
    }
   ],
   "source": [
    "# Define batch size (e.g., 50 tickers per execution)\n",
    "batch_size = 50\n",
    "tickers_to_process = new_tickers[:batch_size]\n",
    "\n",
    "print(f\"Total tickers in Wikipedia table: {len(all_tickers)}\")\n",
    "print(f\"Tickers already processed in raw_prices: {len(processed_tickers)}\")\n",
    "print(f\"New tickers to process in this batch: {len(tickers_to_process)}\")\n",
    "print(\"Tickers in current batch:\", tickers_to_process)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_eod_prices(symbol, start=\"2005-01-01\", end=None, resample_freq=\"daily\"):\n",
    "    \"\"\"\n",
    "    Fetch historical EOD price data for a given symbol from the Tiingo API.\n",
    "    Returns a DataFrame with columns: date, open, high, low, close, volume, \n",
    "    adj_open, adj_high, adj_low, adj_close, adj_volume, div_cash, split_factor, symbol.\n",
    "    \"\"\"\n",
    "    TIINGO_KEY = os.getenv('TIINGO_KEY')\n",
    "    if not TIINGO_KEY:\n",
    "        raise Exception(\"TIINGO_KEY not set in the .env file.\")\n",
    "    \n",
    "    # Convert symbol format for Tiingo API (replace periods with hyphens)\n",
    "    tiingo_symbol = symbol.replace('.', '-')\n",
    "    \n",
    "    base_url = f\"https://api.tiingo.com/tiingo/daily/{tiingo_symbol}/prices\"\n",
    "    params = {\n",
    "        'startDate': start,\n",
    "        'format': 'json',\n",
    "        'token': TIINGO_KEY,\n",
    "        'resampleFreq': resample_freq\n",
    "    }\n",
    "    if end:\n",
    "        params['endDate'] = end\n",
    "    \n",
    "    response = requests.get(base_url, params=params, timeout=30)\n",
    "    response.raise_for_status()\n",
    "    data = response.json()\n",
    "    if not data:\n",
    "        raise Exception(f\"No data returned from Tiingo for symbol: {symbol}\")\n",
    "    \n",
    "    df = pd.DataFrame(data)\n",
    "    \n",
    "    # Define all columns we want to keep, including adjusted prices\n",
    "    columns_to_keep = [\n",
    "        'date', \n",
    "        'open', 'high', 'low', 'close', 'volume',\n",
    "        'adjOpen', 'adjHigh', 'adjLow', 'adjClose', 'adjVolume',\n",
    "        'divCash', 'splitFactor'\n",
    "    ]\n",
    "    \n",
    "    # Keep only columns that exist in the response\n",
    "    df = df[[col for col in columns_to_keep if col in df.columns]]\n",
    "    \n",
    "    # Rename columns to match our database schema\n",
    "    column_mapping = {\n",
    "        'adjOpen': 'adj_open',\n",
    "        'adjHigh': 'adj_high',\n",
    "        'adjLow': 'adj_low',\n",
    "        'adjClose': 'adj_close',\n",
    "        'adjVolume': 'adj_volume',\n",
    "        'divCash': 'div_cash',\n",
    "        'splitFactor': 'split_factor'\n",
    "    }\n",
    "    df = df.rename(columns=column_mapping)\n",
    "    \n",
    "    # Convert date to datetime\n",
    "    df['date'] = pd.to_datetime(df['date'])\n",
    "    \n",
    "    # Convert numeric columns\n",
    "    price_columns = ['open', 'high', 'low', 'close', \n",
    "                    'adj_open', 'adj_high', 'adj_low', 'adj_close',\n",
    "                    'div_cash', 'split_factor']\n",
    "    for col in price_columns:\n",
    "        if col in df.columns:\n",
    "            df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "    \n",
    "    # Convert volume columns\n",
    "    volume_columns = ['volume', 'adj_volume']\n",
    "    for col in volume_columns:\n",
    "        if col in df.columns:\n",
    "            df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "    \n",
    "    # Add symbol column\n",
    "    df['symbol'] = symbol\n",
    "    \n",
    "    # Sort by date and reset index\n",
    "    df = df.sort_values('date').reset_index(drop=True)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing symbol: CNP\n",
      "Symbol CNP processed successfully.\n",
      "Processing symbol: COF\n",
      "Symbol COF processed successfully.\n",
      "Processing symbol: COO\n",
      "Symbol COO processed successfully.\n",
      "Processing symbol: COP\n",
      "Symbol COP processed successfully.\n",
      "Processing symbol: COR\n",
      "Symbol COR processed successfully.\n",
      "Processing symbol: COST\n",
      "Symbol COST processed successfully.\n",
      "Processing symbol: CPAY\n",
      "Symbol CPAY processed successfully.\n",
      "Processing symbol: CPB\n",
      "Symbol CPB processed successfully.\n",
      "Processing symbol: CPRT\n",
      "Symbol CPRT processed successfully.\n",
      "Processing symbol: CPT\n",
      "Symbol CPT processed successfully.\n",
      "Processing symbol: CRL\n",
      "Symbol CRL processed successfully.\n",
      "Processing symbol: CRM\n",
      "Symbol CRM processed successfully.\n",
      "Processing symbol: CRWD\n",
      "Symbol CRWD processed successfully.\n",
      "Processing symbol: CSCO\n",
      "Symbol CSCO processed successfully.\n",
      "Processing symbol: CSGP\n",
      "Symbol CSGP processed successfully.\n",
      "Processing symbol: CSX\n",
      "Symbol CSX processed successfully.\n",
      "Processing symbol: CTAS\n",
      "Symbol CTAS processed successfully.\n",
      "Processing symbol: CTRA\n",
      "Symbol CTRA processed successfully.\n",
      "Processing symbol: CTSH\n",
      "Symbol CTSH processed successfully.\n",
      "Processing symbol: CTVA\n",
      "Symbol CTVA processed successfully.\n",
      "Processing symbol: CVS\n",
      "Symbol CVS processed successfully.\n",
      "Processing symbol: CVX\n",
      "Symbol CVX processed successfully.\n",
      "Processing symbol: CZR\n",
      "Symbol CZR processed successfully.\n",
      "Processing symbol: D\n",
      "Symbol D processed successfully.\n",
      "Processing symbol: DAL\n",
      "Symbol DAL processed successfully.\n",
      "Processing symbol: DASH\n",
      "Symbol DASH processed successfully.\n",
      "Processing symbol: DAY\n",
      "Symbol DAY processed successfully.\n",
      "Processing symbol: DD\n",
      "Symbol DD processed successfully.\n",
      "Processing symbol: DE\n",
      "Symbol DE processed successfully.\n",
      "Processing symbol: DECK\n",
      "Symbol DECK processed successfully.\n",
      "Processing symbol: DELL\n",
      "Symbol DELL processed successfully.\n",
      "Processing symbol: DFS\n",
      "Symbol DFS processed successfully.\n",
      "Processing symbol: DG\n",
      "Symbol DG processed successfully.\n",
      "Processing symbol: DGX\n",
      "Symbol DGX processed successfully.\n",
      "Processing symbol: DHI\n",
      "Symbol DHI processed successfully.\n",
      "Processing symbol: DHR\n",
      "Symbol DHR processed successfully.\n",
      "Processing symbol: DIS\n",
      "Symbol DIS processed successfully.\n",
      "Processing symbol: DLR\n",
      "Symbol DLR processed successfully.\n",
      "Processing symbol: DLTR\n",
      "Symbol DLTR processed successfully.\n",
      "Processing symbol: DOC\n",
      "Symbol DOC processed successfully.\n",
      "Processing symbol: DOV\n",
      "Symbol DOV processed successfully.\n",
      "Processing symbol: DOW\n",
      "Symbol DOW processed successfully.\n",
      "Processing symbol: DPZ\n",
      "Symbol DPZ processed successfully.\n",
      "Processing symbol: DRI\n",
      "Symbol DRI processed successfully.\n",
      "Processing symbol: DTE\n",
      "Symbol DTE processed successfully.\n",
      "Processing symbol: DUK\n",
      "Symbol DUK processed successfully.\n",
      "Processing symbol: DVA\n",
      "Symbol DVA processed successfully.\n",
      "Processing symbol: DVN\n",
      "Symbol DVN processed successfully.\n",
      "Processing symbol: DXCM\n",
      "Symbol DXCM processed successfully.\n",
      "Processing symbol: EA\n",
      "Symbol EA processed successfully.\n",
      "Batch processing complete. Run this cell again after one hour for the next batch.\n"
     ]
    }
   ],
   "source": [
    "for symbol in tickers_to_process:\n",
    "    try:\n",
    "        print(f\"Processing symbol: {symbol}\")\n",
    "        df_symbol = get_eod_prices(symbol)\n",
    "        # Wrap the insertion in a transaction so that each is rolled back if an error occurs.\n",
    "        with engine.begin() as connection:\n",
    "            df_symbol.to_sql(name=\"raw_prices\", con=connection, if_exists=\"append\", index=False)\n",
    "        print(f\"Symbol {symbol} processed successfully.\")\n",
    "    except IntegrityError as ie:\n",
    "        # Duplicate entry (error code 1062) likely means data for those dates already exists.\n",
    "        if \"Duplicate entry\" in str(ie):\n",
    "            print(f\"Duplicate entry error for {symbol}. Skipping insertion.\")\n",
    "        else:\n",
    "            print(f\"IntegrityError processing symbol {symbol}: {ie}\")\n",
    "    except OperationalError as oe:\n",
    "        print(f\"OperationalError processing symbol {symbol}: {oe}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing symbol {symbol}: {e}\")\n",
    "    time.sleep(1)  # Delay between requests\n",
    "\n",
    "print(\"Batch processing complete. Run this cell again after one hour for the next batch.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
