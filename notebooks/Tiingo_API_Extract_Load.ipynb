{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary modules\n",
    "import os\n",
    "import requests\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine, text\n",
    "from dotenv import load_dotenv\n",
    "import time\n",
    "from pymysql.err import IntegrityError, OperationalError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load environment variables from .env\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Establish a database connection using SQLAlchemy and credentials from the .env file\n",
    "DB_USER = os.getenv('DB_USER')\n",
    "DB_PASSWORD = os.getenv('DB_PASSWORD')\n",
    "DB_HOST = os.getenv('DB_HOST')\n",
    "DB_PORT = os.getenv('DB_PORT')\n",
    "DB_NAME = os.getenv('DB_NAME')\n",
    "\n",
    "if None in (DB_USER, DB_PASSWORD, DB_HOST, DB_PORT, DB_NAME):\n",
    "    raise Exception(\"Database credentials are not fully set in the .env file.\")\n",
    "\n",
    "engine = create_engine(f'mysql+pymysql://{DB_USER}:{DB_PASSWORD}@{DB_HOST}:{DB_PORT}/{DB_NAME}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Query tickers from raw_wikipedia_sp500 ---\n",
    "with engine.connect() as conn:\n",
    "    query_wiki = text(\"SELECT DISTINCT symbol FROM raw_wikipedia_sp500\")\n",
    "    df_wiki = pd.read_sql(query_wiki, conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize ticker symbols: strip any extra whitespace and convert to uppercase\n",
    "df_wiki['symbol'] = df_wiki['symbol'].str.strip().str.upper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Query tickers already in raw_prices ---\n",
    "with engine.connect() as conn:\n",
    "    query_prices = text(\"SELECT DISTINCT symbol FROM raw_prices\")\n",
    "    df_prices = pd.read_sql(query_prices, conn)\n",
    "\n",
    "if not df_prices.empty:\n",
    "    processed_tickers = set(df_prices['symbol'].str.strip().str.upper())\n",
    "else:\n",
    "    processed_tickers = set()\n",
    "\n",
    "all_tickers = set(df_wiki['symbol'])\n",
    "new_tickers = list(all_tickers - processed_tickers)\n",
    "new_tickers.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total tickers in Wikipedia table: 503\n",
      "Tickers already processed in raw_prices: 400\n",
      "New tickers to process in this batch: 50\n",
      "Tickers in current batch: ['ROST', 'RSG', 'RTX', 'RVTY', 'SBAC', 'SBUX', 'SCHW', 'SHW', 'SJM', 'SLB', 'SMCI', 'SNA', 'SNPS', 'SO', 'SOLV', 'SPG', 'SPGI', 'SRE', 'STE', 'STLD', 'STT', 'STX', 'STZ', 'SW', 'SWK', 'SWKS', 'SYF', 'SYK', 'SYY', 'T', 'TAP', 'TDG', 'TDY', 'TECH', 'TEL', 'TER', 'TFC', 'TGT', 'TJX', 'TKO', 'TMO', 'TMUS', 'TPL', 'TPR', 'TRGP', 'TRMB', 'TROW', 'TRV', 'TSCO', 'TSLA']\n"
     ]
    }
   ],
   "source": [
    "# Define batch size (e.g., 50 tickers per execution)\n",
    "batch_size = 50\n",
    "tickers_to_process = new_tickers[:batch_size]\n",
    "\n",
    "print(f\"Total tickers in Wikipedia table: {len(all_tickers)}\")\n",
    "print(f\"Tickers already processed in raw_prices: {len(processed_tickers)}\")\n",
    "print(f\"New tickers to process in this batch: {len(tickers_to_process)}\")\n",
    "print(\"Tickers in current batch:\", tickers_to_process)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_eod_prices(symbol, start=\"2005-01-01\", end=None, resample_freq=\"daily\"):\n",
    "    \"\"\"\n",
    "    Fetch historical EOD price data for a given symbol from the Tiingo API.\n",
    "    Returns a DataFrame with columns: date, open, high, low, close, volume, \n",
    "    adj_open, adj_high, adj_low, adj_close, adj_volume, div_cash, split_factor, symbol.\n",
    "    \"\"\"\n",
    "    TIINGO_KEY = os.getenv('TIINGO_KEY')\n",
    "    if not TIINGO_KEY:\n",
    "        raise Exception(\"TIINGO_KEY not set in the .env file.\")\n",
    "    \n",
    "    # Convert symbol format for Tiingo API (replace periods with hyphens)\n",
    "    tiingo_symbol = symbol.replace('.', '-')\n",
    "    \n",
    "    base_url = f\"https://api.tiingo.com/tiingo/daily/{tiingo_symbol}/prices\"\n",
    "    params = {\n",
    "        'startDate': start,\n",
    "        'format': 'json',\n",
    "        'token': TIINGO_KEY,\n",
    "        'resampleFreq': resample_freq\n",
    "    }\n",
    "    if end:\n",
    "        params['endDate'] = end\n",
    "    \n",
    "    response = requests.get(base_url, params=params, timeout=30)\n",
    "    response.raise_for_status()\n",
    "    data = response.json()\n",
    "    if not data:\n",
    "        raise Exception(f\"No data returned from Tiingo for symbol: {symbol}\")\n",
    "    \n",
    "    df = pd.DataFrame(data)\n",
    "    \n",
    "    # Define all columns we want to keep, including adjusted prices\n",
    "    columns_to_keep = [\n",
    "        'date', \n",
    "        'open', 'high', 'low', 'close', 'volume',\n",
    "        'adjOpen', 'adjHigh', 'adjLow', 'adjClose', 'adjVolume',\n",
    "        'divCash', 'splitFactor'\n",
    "    ]\n",
    "    \n",
    "    # Keep only columns that exist in the response\n",
    "    df = df[[col for col in columns_to_keep if col in df.columns]]\n",
    "    \n",
    "    # Rename columns to match our database schema\n",
    "    column_mapping = {\n",
    "        'adjOpen': 'adj_open',\n",
    "        'adjHigh': 'adj_high',\n",
    "        'adjLow': 'adj_low',\n",
    "        'adjClose': 'adj_close',\n",
    "        'adjVolume': 'adj_volume',\n",
    "        'divCash': 'div_cash',\n",
    "        'splitFactor': 'split_factor'\n",
    "    }\n",
    "    df = df.rename(columns=column_mapping)\n",
    "    \n",
    "    # Convert date to datetime\n",
    "    df['date'] = pd.to_datetime(df['date'])\n",
    "    \n",
    "    # Convert numeric columns\n",
    "    price_columns = ['open', 'high', 'low', 'close', \n",
    "                    'adj_open', 'adj_high', 'adj_low', 'adj_close',\n",
    "                    'div_cash', 'split_factor']\n",
    "    for col in price_columns:\n",
    "        if col in df.columns:\n",
    "            df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "    \n",
    "    # Convert volume columns\n",
    "    volume_columns = ['volume', 'adj_volume']\n",
    "    for col in volume_columns:\n",
    "        if col in df.columns:\n",
    "            df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "    \n",
    "    # Add symbol column\n",
    "    df['symbol'] = symbol\n",
    "    \n",
    "    # Sort by date and reset index\n",
    "    df = df.sort_values('date').reset_index(drop=True)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing symbol: ROST\n",
      "Symbol ROST processed successfully.\n",
      "Processing symbol: RSG\n",
      "Symbol RSG processed successfully.\n",
      "Processing symbol: RTX\n",
      "Symbol RTX processed successfully.\n",
      "Processing symbol: RVTY\n",
      "Symbol RVTY processed successfully.\n",
      "Processing symbol: SBAC\n",
      "Symbol SBAC processed successfully.\n",
      "Processing symbol: SBUX\n",
      "Symbol SBUX processed successfully.\n",
      "Processing symbol: SCHW\n",
      "Symbol SCHW processed successfully.\n",
      "Processing symbol: SHW\n",
      "Symbol SHW processed successfully.\n",
      "Processing symbol: SJM\n",
      "Symbol SJM processed successfully.\n",
      "Processing symbol: SLB\n",
      "Symbol SLB processed successfully.\n",
      "Processing symbol: SMCI\n",
      "Symbol SMCI processed successfully.\n",
      "Processing symbol: SNA\n",
      "Symbol SNA processed successfully.\n",
      "Processing symbol: SNPS\n",
      "Symbol SNPS processed successfully.\n",
      "Processing symbol: SO\n",
      "Symbol SO processed successfully.\n",
      "Processing symbol: SOLV\n",
      "Symbol SOLV processed successfully.\n",
      "Processing symbol: SPG\n",
      "Symbol SPG processed successfully.\n",
      "Processing symbol: SPGI\n",
      "Symbol SPGI processed successfully.\n",
      "Processing symbol: SRE\n",
      "Symbol SRE processed successfully.\n",
      "Processing symbol: STE\n",
      "Symbol STE processed successfully.\n",
      "Processing symbol: STLD\n",
      "Symbol STLD processed successfully.\n",
      "Processing symbol: STT\n",
      "Symbol STT processed successfully.\n",
      "Processing symbol: STX\n",
      "Symbol STX processed successfully.\n",
      "Processing symbol: STZ\n",
      "Symbol STZ processed successfully.\n",
      "Processing symbol: SW\n",
      "Symbol SW processed successfully.\n",
      "Processing symbol: SWK\n",
      "Symbol SWK processed successfully.\n",
      "Processing symbol: SWKS\n",
      "Symbol SWKS processed successfully.\n",
      "Processing symbol: SYF\n",
      "Symbol SYF processed successfully.\n",
      "Processing symbol: SYK\n",
      "Symbol SYK processed successfully.\n",
      "Processing symbol: SYY\n",
      "Symbol SYY processed successfully.\n",
      "Processing symbol: T\n",
      "Symbol T processed successfully.\n",
      "Processing symbol: TAP\n",
      "Symbol TAP processed successfully.\n",
      "Processing symbol: TDG\n",
      "Symbol TDG processed successfully.\n",
      "Processing symbol: TDY\n",
      "Symbol TDY processed successfully.\n",
      "Processing symbol: TECH\n",
      "Symbol TECH processed successfully.\n",
      "Processing symbol: TEL\n",
      "Symbol TEL processed successfully.\n",
      "Processing symbol: TER\n",
      "Symbol TER processed successfully.\n",
      "Processing symbol: TFC\n",
      "Symbol TFC processed successfully.\n",
      "Processing symbol: TGT\n",
      "Symbol TGT processed successfully.\n",
      "Processing symbol: TJX\n",
      "Symbol TJX processed successfully.\n",
      "Processing symbol: TKO\n",
      "Symbol TKO processed successfully.\n",
      "Processing symbol: TMO\n",
      "Symbol TMO processed successfully.\n",
      "Processing symbol: TMUS\n",
      "Symbol TMUS processed successfully.\n",
      "Processing symbol: TPL\n",
      "Symbol TPL processed successfully.\n",
      "Processing symbol: TPR\n",
      "Symbol TPR processed successfully.\n",
      "Processing symbol: TRGP\n",
      "Symbol TRGP processed successfully.\n",
      "Processing symbol: TRMB\n",
      "Symbol TRMB processed successfully.\n",
      "Processing symbol: TROW\n",
      "Symbol TROW processed successfully.\n",
      "Processing symbol: TRV\n",
      "Symbol TRV processed successfully.\n",
      "Processing symbol: TSCO\n",
      "Symbol TSCO processed successfully.\n",
      "Processing symbol: TSLA\n",
      "Symbol TSLA processed successfully.\n",
      "Batch processing complete. Run this cell again after one hour for the next batch.\n"
     ]
    }
   ],
   "source": [
    "for symbol in tickers_to_process:\n",
    "    try:\n",
    "        print(f\"Processing symbol: {symbol}\")\n",
    "        df_symbol = get_eod_prices(symbol)\n",
    "        # Wrap the insertion in a transaction so that each is rolled back if an error occurs.\n",
    "        with engine.begin() as connection:\n",
    "            df_symbol.to_sql(name=\"raw_prices\", con=connection, if_exists=\"append\", index=False)\n",
    "        print(f\"Symbol {symbol} processed successfully.\")\n",
    "    except IntegrityError as ie:\n",
    "        # Duplicate entry (error code 1062) likely means data for those dates already exists.\n",
    "        if \"Duplicate entry\" in str(ie):\n",
    "            print(f\"Duplicate entry error for {symbol}. Skipping insertion.\")\n",
    "        else:\n",
    "            print(f\"IntegrityError processing symbol {symbol}: {ie}\")\n",
    "    except OperationalError as oe:\n",
    "        print(f\"OperationalError processing symbol {symbol}: {oe}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing symbol {symbol}: {e}\")\n",
    "    time.sleep(1)  # Delay between requests\n",
    "\n",
    "print(\"Batch processing complete. Run this cell again after one hour for the next batch.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
