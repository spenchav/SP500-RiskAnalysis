{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary modules\n",
    "import os\n",
    "import requests\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine, text\n",
    "from dotenv import load_dotenv\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load environment variables from .env\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Establish a database connection using SQLAlchemy and credentials from the .env file\n",
    "DB_USER = os.getenv('DB_USER')\n",
    "DB_PASSWORD = os.getenv('DB_PASSWORD')\n",
    "DB_HOST = os.getenv('DB_HOST')\n",
    "DB_PORT = os.getenv('DB_PORT')\n",
    "DB_NAME = os.getenv('DB_NAME')\n",
    "\n",
    "if None in (DB_USER, DB_PASSWORD, DB_HOST, DB_PORT, DB_NAME):\n",
    "    raise Exception(\"Database credentials are not fully set in the .env file.\")\n",
    "\n",
    "engine = create_engine(f'mysql+pymysql://{DB_USER}:{DB_PASSWORD}@{DB_HOST}:{DB_PORT}/{DB_NAME}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Query tickers from raw_wikipedia_sp500 ---\n",
    "with engine.connect() as conn:\n",
    "    query_wiki = text(\"SELECT DISTINCT symbol FROM raw_wikipedia_sp500\")\n",
    "    df_wiki = pd.read_sql(query_wiki, conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize ticker symbols: strip any extra whitespace and convert to uppercase\n",
    "df_wiki['symbol'] = df_wiki['symbol'].str.strip().str.upper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Query tickers already processed in raw_prices ---\n",
    "with engine.connect() as conn:\n",
    "    query_prices = text(\"SELECT DISTINCT symbol FROM raw_prices\")\n",
    "    df_prices = pd.read_sql(query_prices, conn)\n",
    "\n",
    "if not df_prices.empty:\n",
    "    processed_tickers = set(df_prices['symbol'].str.strip().str.upper())\n",
    "else:\n",
    "    processed_tickers = set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the set difference: tickers in Wikipedia that are not yet in raw_prices\n",
    "all_tickers = set(df_wiki['symbol'])\n",
    "new_tickers = list(all_tickers - processed_tickers)\n",
    "new_tickers.sort()  # Optional: sort for consistency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total tickers in Wikipedia table: 503\n",
      "Tickers already processed in raw_prices: 1\n",
      "New tickers to process in this batch: 50\n",
      "Tickers in current batch: ['A', 'ABBV', 'ABNB', 'ABT', 'ACGL', 'ACN', 'ADBE', 'ADI', 'ADM', 'ADP', 'ADSK', 'AEE', 'AEP', 'AES', 'AFL', 'AIG', 'AIZ', 'AJG', 'AKAM', 'ALB', 'ALGN', 'ALL', 'ALLE', 'AMAT', 'AMCR', 'AMD', 'AME', 'AMGN', 'AMP', 'AMT', 'AMZN', 'ANET', 'ANSS', 'AON', 'AOS', 'APA', 'APD', 'APH', 'APO', 'APTV', 'ARE', 'ATO', 'AVB', 'AVGO', 'AVY', 'AWK', 'AXON', 'AXP', 'AZO', 'BA']\n"
     ]
    }
   ],
   "source": [
    "# Define batch size (e.g., 50 tickers per execution)\n",
    "batch_size = 50\n",
    "tickers_to_process = new_tickers[:batch_size]\n",
    "\n",
    "print(f\"Total tickers in Wikipedia table: {len(all_tickers)}\")\n",
    "print(f\"Tickers already processed in raw_prices: {len(processed_tickers)}\")\n",
    "print(f\"New tickers to process in this batch: {len(tickers_to_process)}\")\n",
    "print(\"Tickers in current batch:\", tickers_to_process)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defines get_eod_prices function \n",
    "def get_eod_prices(symbol, start=\"2019-01-01\", end=None, resample_freq=\"daily\"):\n",
    "    \"\"\"\n",
    "    Fetches historical EOD price data for a given symbol from the Tiingo API\n",
    "    and returns a DataFrame with columns: trade_date, open, high, low, close, volume, symbol.\n",
    "    \"\"\"\n",
    "    import requests\n",
    "    import pandas as pd\n",
    "    TIINGO_KEY = os.getenv('TIINGO_KEY')\n",
    "    if not TIINGO_KEY:\n",
    "        raise Exception(\"TIINGO_KEY not set in the .env file.\")\n",
    "    \n",
    "    base_url = f\"https://api.tiingo.com/tiingo/daily/{symbol}/prices\"\n",
    "    params = {\n",
    "        'startDate': start,\n",
    "        'format': 'json',\n",
    "        'token': TIINGO_KEY,\n",
    "        'resampleFreq': resample_freq\n",
    "    }\n",
    "    if end:\n",
    "        params['endDate'] = end\n",
    "    response = requests.get(base_url, params=params, timeout=30)\n",
    "    response.raise_for_status()\n",
    "    data = response.json()\n",
    "    if not data:\n",
    "        raise Exception(f\"No data returned from Tiingo for symbol: {symbol}\")\n",
    "    df = pd.DataFrame(data)\n",
    "    # Keep only necessary columns; note: column 'date' will be renamed to 'trade_date'\n",
    "    columns_to_keep = ['date', 'open', 'high', 'low', 'close', 'volume']\n",
    "    df = df[[col for col in columns_to_keep if col in df.columns]]\n",
    "    df['date'] = pd.to_datetime(df['date'])\n",
    "    for col in ['open', 'high', 'low', 'close']:\n",
    "        df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "    if 'volume' in df.columns:\n",
    "        df['volume'] = pd.to_numeric(df['volume'], errors='coerce')\n",
    "    # Rename 'date' to 'trade_date' to match our table schema\n",
    "    df.rename(columns={'date': 'date'}, inplace=True)\n",
    "    df['symbol'] = symbol\n",
    "    df = df.sort_values('date').reset_index(drop=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing symbol: A\n",
      "Error processing A: (pymysql.err.IntegrityError) (1062, \"Duplicate entry 'A-2019-01-02' for key 'raw_prices.PRIMARY'\")\n",
      "[SQL: INSERT INTO raw_prices (date, open, high, low, close, volume, symbol) VALUES (%(date)s, %(open)s, %(high)s, %(low)s, %(close)s, %(volume)s, %(symbol)s)]\n",
      "[parameters: [{'date': datetime.datetime(2019, 1, 2, 0, 0, tzinfo=datetime.timezone.utc), 'open': 66.5, 'high': 66.57, 'low': 65.3, 'close': 65.69, 'volume': 2113304, 'symbol': 'A'}, {'date': datetime.datetime(2019, 1, 3, 0, 0, tzinfo=datetime.timezone.utc), 'open': 65.53, 'high': 65.78, 'low': 62.0, 'close': 63.27, 'volume': 5383926, 'symbol': 'A'}, {'date': datetime.datetime(2019, 1, 4, 0, 0, tzinfo=datetime.timezone.utc), 'open': 64.09, 'high': 65.95, 'low': 64.09, 'close': 65.46, 'volume': 3123654, 'symbol': 'A'}, {'date': datetime.datetime(2019, 1, 7, 0, 0, tzinfo=datetime.timezone.utc), 'open': 65.64, 'high': 67.43, 'low': 65.61, 'close': 66.85, 'volume': 3235055, 'symbol': 'A'}, {'date': datetime.datetime(2019, 1, 8, 0, 0, tzinfo=datetime.timezone.utc), 'open': 67.59, 'high': 68.21, 'low': 66.7, 'close': 67.83, 'volume': 1578055, 'symbol': 'A'}, {'date': datetime.datetime(2019, 1, 9, 0, 0, tzinfo=datetime.timezone.utc), 'open': 68.2, 'high': 69.66, 'low': 68.0, 'close': 69.25, 'volume': 2442291, 'symbol': 'A'}, {'date': datetime.datetime(2019, 1, 10, 0, 0, tzinfo=datetime.timezone.utc), 'open': 69.05, 'high': 69.95, 'low': 68.6, 'close': 69.9, 'volume': 1080882, 'symbol': 'A'}, {'date': datetime.datetime(2019, 1, 11, 0, 0, tzinfo=datetime.timezone.utc), 'open': 69.29, 'high': 70.41, 'low': 68.94, 'close': 70.38, 'volume': 1210791, 'symbol': 'A'}  ... displaying 10 of 1577 total bound parameter sets ...  {'date': datetime.datetime(2025, 4, 8, 0, 0, tzinfo=datetime.timezone.utc), 'open': 106.06, 'high': 106.76, 'low': 97.37, 'close': 99.29, 'volume': 4525196, 'symbol': 'A'}, {'date': datetime.datetime(2025, 4, 9, 0, 0, tzinfo=datetime.timezone.utc), 'open': 98.06, 'high': 107.2982, 'low': 96.43, 'close': 107.05, 'volume': 4234699, 'symbol': 'A'}]]\n",
      "(Background on this error at: https://sqlalche.me/e/20/gkpj)\n",
      "Processing symbol: ABBV\n",
      "Symbol ABBV processed successfully.\n",
      "Processing symbol: ABNB\n",
      "Symbol ABNB processed successfully.\n",
      "Processing symbol: ABT\n",
      "Symbol ABT processed successfully.\n",
      "Processing symbol: ACGL\n",
      "Symbol ACGL processed successfully.\n",
      "Processing symbol: ACN\n",
      "Symbol ACN processed successfully.\n",
      "Processing symbol: ADBE\n",
      "Symbol ADBE processed successfully.\n",
      "Processing symbol: ADI\n",
      "Symbol ADI processed successfully.\n",
      "Processing symbol: ADM\n",
      "Symbol ADM processed successfully.\n",
      "Processing symbol: ADP\n",
      "Symbol ADP processed successfully.\n",
      "Processing symbol: ADSK\n",
      "Symbol ADSK processed successfully.\n",
      "Processing symbol: AEE\n",
      "Symbol AEE processed successfully.\n",
      "Processing symbol: AEP\n",
      "Symbol AEP processed successfully.\n",
      "Processing symbol: AES\n",
      "Symbol AES processed successfully.\n",
      "Processing symbol: AFL\n",
      "Symbol AFL processed successfully.\n",
      "Processing symbol: AIG\n",
      "Symbol AIG processed successfully.\n",
      "Processing symbol: AIZ\n",
      "Symbol AIZ processed successfully.\n",
      "Processing symbol: AJG\n",
      "Symbol AJG processed successfully.\n",
      "Processing symbol: AKAM\n",
      "Symbol AKAM processed successfully.\n",
      "Processing symbol: ALB\n",
      "Symbol ALB processed successfully.\n",
      "Processing symbol: ALGN\n",
      "Symbol ALGN processed successfully.\n",
      "Processing symbol: ALL\n",
      "Symbol ALL processed successfully.\n",
      "Processing symbol: ALLE\n",
      "Symbol ALLE processed successfully.\n",
      "Processing symbol: AMAT\n",
      "Symbol AMAT processed successfully.\n",
      "Processing symbol: AMCR\n",
      "Symbol AMCR processed successfully.\n",
      "Processing symbol: AMD\n",
      "Symbol AMD processed successfully.\n",
      "Processing symbol: AME\n",
      "Symbol AME processed successfully.\n",
      "Processing symbol: AMGN\n",
      "Symbol AMGN processed successfully.\n",
      "Processing symbol: AMP\n",
      "Symbol AMP processed successfully.\n",
      "Processing symbol: AMT\n",
      "Symbol AMT processed successfully.\n",
      "Processing symbol: AMZN\n",
      "Symbol AMZN processed successfully.\n",
      "Processing symbol: ANET\n",
      "Symbol ANET processed successfully.\n",
      "Processing symbol: ANSS\n",
      "Symbol ANSS processed successfully.\n",
      "Processing symbol: AON\n",
      "Symbol AON processed successfully.\n",
      "Processing symbol: AOS\n",
      "Symbol AOS processed successfully.\n",
      "Processing symbol: APA\n",
      "Symbol APA processed successfully.\n",
      "Processing symbol: APD\n",
      "Symbol APD processed successfully.\n",
      "Processing symbol: APH\n",
      "Symbol APH processed successfully.\n",
      "Processing symbol: APO\n",
      "Symbol APO processed successfully.\n",
      "Processing symbol: APTV\n",
      "Symbol APTV processed successfully.\n",
      "Processing symbol: ARE\n",
      "Symbol ARE processed successfully.\n",
      "Processing symbol: ATO\n",
      "Symbol ATO processed successfully.\n",
      "Processing symbol: AVB\n",
      "Symbol AVB processed successfully.\n",
      "Processing symbol: AVGO\n",
      "Symbol AVGO processed successfully.\n",
      "Processing symbol: AVY\n",
      "Symbol AVY processed successfully.\n",
      "Processing symbol: AWK\n",
      "Symbol AWK processed successfully.\n",
      "Processing symbol: AXON\n",
      "Symbol AXON processed successfully.\n",
      "Processing symbol: AXP\n",
      "Symbol AXP processed successfully.\n",
      "Processing symbol: AZO\n",
      "Symbol AZO processed successfully.\n",
      "Processing symbol: BA\n",
      "Symbol BA processed successfully.\n",
      "Batch processing complete. Run this cell again after one hour to process the next batch.\n"
     ]
    }
   ],
   "source": [
    "# Process each ticker in the current batch \n",
    "for symbol in tickers_to_process:\n",
    "    try:\n",
    "        print(f\"Processing symbol: {symbol}\")\n",
    "        df_symbol = get_eod_prices(symbol)\n",
    "        # Insert the fetched DataFrame into the raw_prices table (append new data)\n",
    "        df_symbol.to_sql(name=\"raw_prices\", con=engine, if_exists=\"append\", index=False)\n",
    "        print(f\"Symbol {symbol} processed successfully.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {symbol}: {e}\")\n",
    "    # Short delay between requests to be gentle on the API\n",
    "    time.sleep(1)\n",
    "\n",
    "print(\"Batch processing complete. Run this cell again after one hour to process the next batch.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
