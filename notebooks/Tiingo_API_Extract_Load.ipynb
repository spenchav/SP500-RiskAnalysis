{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary modules\n",
    "import os\n",
    "import requests\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine, text\n",
    "from dotenv import load_dotenv\n",
    "import time\n",
    "from pymysql.err import IntegrityError, OperationalError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load environment variables from .env\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Establish a database connection using SQLAlchemy and credentials from the .env file\n",
    "DB_USER = os.getenv('DB_USER')\n",
    "DB_PASSWORD = os.getenv('DB_PASSWORD')\n",
    "DB_HOST = os.getenv('DB_HOST')\n",
    "DB_PORT = os.getenv('DB_PORT')\n",
    "DB_NAME = os.getenv('DB_NAME')\n",
    "\n",
    "if None in (DB_USER, DB_PASSWORD, DB_HOST, DB_PORT, DB_NAME):\n",
    "    raise Exception(\"Database credentials are not fully set in the .env file.\")\n",
    "\n",
    "engine = create_engine(f'mysql+pymysql://{DB_USER}:{DB_PASSWORD}@{DB_HOST}:{DB_PORT}/{DB_NAME}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Query tickers from raw_wikipedia_sp500 ---\n",
    "with engine.connect() as conn:\n",
    "    query_wiki = text(\"SELECT DISTINCT symbol FROM raw_wikipedia_sp500\")\n",
    "    df_wiki = pd.read_sql(query_wiki, conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize ticker symbols: strip any extra whitespace and convert to uppercase\n",
    "df_wiki['symbol'] = df_wiki['symbol'].str.strip().str.upper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Query tickers already in raw_prices ---\n",
    "with engine.connect() as conn:\n",
    "    query_prices = text(\"SELECT DISTINCT symbol FROM raw_prices\")\n",
    "    df_prices = pd.read_sql(query_prices, conn)\n",
    "\n",
    "if not df_prices.empty:\n",
    "    processed_tickers = set(df_prices['symbol'].str.strip().str.upper())\n",
    "else:\n",
    "    processed_tickers = set()\n",
    "\n",
    "all_tickers = set(df_wiki['symbol'])\n",
    "new_tickers = list(all_tickers - processed_tickers)\n",
    "new_tickers.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total tickers in Wikipedia table: 503\n",
      "Tickers already processed in raw_prices: 0\n",
      "New tickers to process in this batch: 50\n",
      "Tickers in current batch: ['A', 'AAPL', 'ABBV', 'ABNB', 'ABT', 'ACGL', 'ACN', 'ADBE', 'ADI', 'ADM', 'ADP', 'ADSK', 'AEE', 'AEP', 'AES', 'AFL', 'AIG', 'AIZ', 'AJG', 'AKAM', 'ALB', 'ALGN', 'ALL', 'ALLE', 'AMAT', 'AMCR', 'AMD', 'AME', 'AMGN', 'AMP', 'AMT', 'AMZN', 'ANET', 'ANSS', 'AON', 'AOS', 'APA', 'APD', 'APH', 'APO', 'APTV', 'ARE', 'ATO', 'AVB', 'AVGO', 'AVY', 'AWK', 'AXON', 'AXP', 'AZO']\n"
     ]
    }
   ],
   "source": [
    "# Define batch size (e.g., 50 tickers per execution)\n",
    "batch_size = 50\n",
    "tickers_to_process = new_tickers[:batch_size]\n",
    "\n",
    "print(f\"Total tickers in Wikipedia table: {len(all_tickers)}\")\n",
    "print(f\"Tickers already processed in raw_prices: {len(processed_tickers)}\")\n",
    "print(f\"New tickers to process in this batch: {len(tickers_to_process)}\")\n",
    "print(\"Tickers in current batch:\", tickers_to_process)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_eod_prices(symbol, start=\"2019-01-01\", end=None, resample_freq=\"daily\"):\n",
    "    \"\"\"\n",
    "    Fetch historical EOD price data for a given symbol from the Tiingo API.\n",
    "    Returns a DataFrame with columns: date, open, high, low, close, volume, \n",
    "    adj_open, adj_high, adj_low, adj_close, adj_volume, div_cash, split_factor, symbol.\n",
    "    \"\"\"\n",
    "    TIINGO_KEY = os.getenv('TIINGO_KEY')\n",
    "    if not TIINGO_KEY:\n",
    "        raise Exception(\"TIINGO_KEY not set in the .env file.\")\n",
    "    \n",
    "    # Convert symbol format for Tiingo API (replace periods with hyphens)\n",
    "    tiingo_symbol = symbol.replace('.', '-')\n",
    "    \n",
    "    base_url = f\"https://api.tiingo.com/tiingo/daily/{tiingo_symbol}/prices\"\n",
    "    params = {\n",
    "        'startDate': start,\n",
    "        'format': 'json',\n",
    "        'token': TIINGO_KEY,\n",
    "        'resampleFreq': resample_freq\n",
    "    }\n",
    "    if end:\n",
    "        params['endDate'] = end\n",
    "    \n",
    "    response = requests.get(base_url, params=params, timeout=30)\n",
    "    response.raise_for_status()\n",
    "    data = response.json()\n",
    "    if not data:\n",
    "        raise Exception(f\"No data returned from Tiingo for symbol: {symbol}\")\n",
    "    \n",
    "    df = pd.DataFrame(data)\n",
    "    \n",
    "    # Define all columns we want to keep, including adjusted prices\n",
    "    columns_to_keep = [\n",
    "        'date', \n",
    "        'open', 'high', 'low', 'close', 'volume',\n",
    "        'adjOpen', 'adjHigh', 'adjLow', 'adjClose', 'adjVolume',\n",
    "        'divCash', 'splitFactor'\n",
    "    ]\n",
    "    \n",
    "    # Keep only columns that exist in the response\n",
    "    df = df[[col for col in columns_to_keep if col in df.columns]]\n",
    "    \n",
    "    # Rename columns to match our database schema\n",
    "    column_mapping = {\n",
    "        'adjOpen': 'adj_open',\n",
    "        'adjHigh': 'adj_high',\n",
    "        'adjLow': 'adj_low',\n",
    "        'adjClose': 'adj_close',\n",
    "        'adjVolume': 'adj_volume',\n",
    "        'divCash': 'div_cash',\n",
    "        'splitFactor': 'split_factor'\n",
    "    }\n",
    "    df = df.rename(columns=column_mapping)\n",
    "    \n",
    "    # Convert date to datetime\n",
    "    df['date'] = pd.to_datetime(df['date'])\n",
    "    \n",
    "    # Convert numeric columns\n",
    "    price_columns = ['open', 'high', 'low', 'close', \n",
    "                    'adj_open', 'adj_high', 'adj_low', 'adj_close',\n",
    "                    'div_cash', 'split_factor']\n",
    "    for col in price_columns:\n",
    "        if col in df.columns:\n",
    "            df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "    \n",
    "    # Convert volume columns\n",
    "    volume_columns = ['volume', 'adj_volume']\n",
    "    for col in volume_columns:\n",
    "        if col in df.columns:\n",
    "            df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "    \n",
    "    # Add symbol column\n",
    "    df['symbol'] = symbol\n",
    "    \n",
    "    # Sort by date and reset index\n",
    "    df = df.sort_values('date').reset_index(drop=True)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing symbol: A\n",
      "Symbol A processed successfully.\n",
      "Processing symbol: AAPL\n",
      "Symbol AAPL processed successfully.\n",
      "Processing symbol: ABBV\n",
      "Symbol ABBV processed successfully.\n",
      "Processing symbol: ABNB\n",
      "Symbol ABNB processed successfully.\n",
      "Processing symbol: ABT\n",
      "Symbol ABT processed successfully.\n",
      "Processing symbol: ACGL\n",
      "Symbol ACGL processed successfully.\n",
      "Processing symbol: ACN\n",
      "Symbol ACN processed successfully.\n",
      "Processing symbol: ADBE\n",
      "Symbol ADBE processed successfully.\n",
      "Processing symbol: ADI\n",
      "Symbol ADI processed successfully.\n",
      "Processing symbol: ADM\n",
      "Symbol ADM processed successfully.\n",
      "Processing symbol: ADP\n",
      "Symbol ADP processed successfully.\n",
      "Processing symbol: ADSK\n",
      "Symbol ADSK processed successfully.\n",
      "Processing symbol: AEE\n",
      "Symbol AEE processed successfully.\n",
      "Processing symbol: AEP\n",
      "Symbol AEP processed successfully.\n",
      "Processing symbol: AES\n",
      "Symbol AES processed successfully.\n",
      "Processing symbol: AFL\n",
      "Symbol AFL processed successfully.\n",
      "Processing symbol: AIG\n",
      "Symbol AIG processed successfully.\n",
      "Processing symbol: AIZ\n",
      "Symbol AIZ processed successfully.\n",
      "Processing symbol: AJG\n",
      "Symbol AJG processed successfully.\n",
      "Processing symbol: AKAM\n",
      "Symbol AKAM processed successfully.\n",
      "Processing symbol: ALB\n",
      "Symbol ALB processed successfully.\n",
      "Processing symbol: ALGN\n",
      "Symbol ALGN processed successfully.\n",
      "Processing symbol: ALL\n",
      "Symbol ALL processed successfully.\n",
      "Processing symbol: ALLE\n",
      "Symbol ALLE processed successfully.\n",
      "Processing symbol: AMAT\n",
      "Symbol AMAT processed successfully.\n",
      "Processing symbol: AMCR\n",
      "Symbol AMCR processed successfully.\n",
      "Processing symbol: AMD\n",
      "Symbol AMD processed successfully.\n",
      "Processing symbol: AME\n",
      "Symbol AME processed successfully.\n",
      "Processing symbol: AMGN\n",
      "Symbol AMGN processed successfully.\n",
      "Processing symbol: AMP\n",
      "Symbol AMP processed successfully.\n",
      "Processing symbol: AMT\n",
      "Symbol AMT processed successfully.\n",
      "Processing symbol: AMZN\n",
      "Symbol AMZN processed successfully.\n",
      "Processing symbol: ANET\n",
      "Symbol ANET processed successfully.\n",
      "Processing symbol: ANSS\n",
      "Symbol ANSS processed successfully.\n",
      "Processing symbol: AON\n",
      "Symbol AON processed successfully.\n",
      "Processing symbol: AOS\n",
      "Symbol AOS processed successfully.\n",
      "Processing symbol: APA\n",
      "Symbol APA processed successfully.\n",
      "Processing symbol: APD\n",
      "Symbol APD processed successfully.\n",
      "Processing symbol: APH\n",
      "Symbol APH processed successfully.\n",
      "Processing symbol: APO\n",
      "Symbol APO processed successfully.\n",
      "Processing symbol: APTV\n",
      "Symbol APTV processed successfully.\n",
      "Processing symbol: ARE\n",
      "Symbol ARE processed successfully.\n",
      "Processing symbol: ATO\n",
      "Symbol ATO processed successfully.\n",
      "Processing symbol: AVB\n",
      "Symbol AVB processed successfully.\n",
      "Processing symbol: AVGO\n",
      "Symbol AVGO processed successfully.\n",
      "Processing symbol: AVY\n",
      "Symbol AVY processed successfully.\n",
      "Processing symbol: AWK\n",
      "Symbol AWK processed successfully.\n",
      "Processing symbol: AXON\n",
      "Symbol AXON processed successfully.\n",
      "Processing symbol: AXP\n",
      "Symbol AXP processed successfully.\n",
      "Processing symbol: AZO\n",
      "Symbol AZO processed successfully.\n",
      "Batch processing complete. Run this cell again after one hour for the next batch.\n"
     ]
    }
   ],
   "source": [
    "for symbol in tickers_to_process:\n",
    "    try:\n",
    "        print(f\"Processing symbol: {symbol}\")\n",
    "        df_symbol = get_eod_prices(symbol)\n",
    "        # Wrap the insertion in a transaction so that each is rolled back if an error occurs.\n",
    "        with engine.begin() as connection:\n",
    "            df_symbol.to_sql(name=\"raw_prices\", con=connection, if_exists=\"append\", index=False)\n",
    "        print(f\"Symbol {symbol} processed successfully.\")\n",
    "    except IntegrityError as ie:\n",
    "        # Duplicate entry (error code 1062) likely means data for those dates already exists.\n",
    "        if \"Duplicate entry\" in str(ie):\n",
    "            print(f\"Duplicate entry error for {symbol}. Skipping insertion.\")\n",
    "        else:\n",
    "            print(f\"IntegrityError processing symbol {symbol}: {ie}\")\n",
    "    except OperationalError as oe:\n",
    "        print(f\"OperationalError processing symbol {symbol}: {oe}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing symbol {symbol}: {e}\")\n",
    "    time.sleep(1)  # Delay between requests\n",
    "\n",
    "print(\"Batch processing complete. Run this cell again after one hour for the next batch.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
