{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary modules\n",
    "import os\n",
    "import requests\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine, text\n",
    "from dotenv import load_dotenv\n",
    "import time\n",
    "from pymysql.err import IntegrityError, OperationalError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load environment variables from .env\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Establish a database connection using SQLAlchemy and credentials from the .env file\n",
    "DB_USER = os.getenv('DB_USER')\n",
    "DB_PASSWORD = os.getenv('DB_PASSWORD')\n",
    "DB_HOST = os.getenv('DB_HOST')\n",
    "DB_PORT = os.getenv('DB_PORT')\n",
    "DB_NAME = os.getenv('DB_NAME')\n",
    "\n",
    "if None in (DB_USER, DB_PASSWORD, DB_HOST, DB_PORT, DB_NAME):\n",
    "    raise Exception(\"Database credentials are not fully set in the .env file.\")\n",
    "\n",
    "engine = create_engine(f'mysql+pymysql://{DB_USER}:{DB_PASSWORD}@{DB_HOST}:{DB_PORT}/{DB_NAME}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Query tickers from raw_wikipedia_sp500 ---\n",
    "with engine.connect() as conn:\n",
    "    query_wiki = text(\"SELECT DISTINCT symbol FROM raw_wikipedia_sp500\")\n",
    "    df_wiki = pd.read_sql(query_wiki, conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize ticker symbols: strip any extra whitespace and convert to uppercase\n",
    "df_wiki['symbol'] = df_wiki['symbol'].str.strip().str.upper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Query tickers already in raw_prices ---\n",
    "with engine.connect() as conn:\n",
    "    query_prices = text(\"SELECT DISTINCT symbol FROM raw_prices\")\n",
    "    df_prices = pd.read_sql(query_prices, conn)\n",
    "\n",
    "if not df_prices.empty:\n",
    "    processed_tickers = set(df_prices['symbol'].str.strip().str.upper())\n",
    "else:\n",
    "    processed_tickers = set()\n",
    "\n",
    "all_tickers = set(df_wiki['symbol'])\n",
    "new_tickers = list(all_tickers - processed_tickers)\n",
    "new_tickers.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total tickers in Wikipedia table: 503\n",
      "Tickers already processed in raw_prices: 250\n",
      "New tickers to process in this batch: 50\n",
      "Tickers in current batch: ['IT', 'ITW', 'IVZ', 'J', 'JBHT', 'JBL', 'JCI', 'JKHY', 'JNJ', 'JNPR', 'JPM', 'K', 'KDP', 'KEY', 'KEYS', 'KHC', 'KIM', 'KKR', 'KLAC', 'KMB', 'KMI', 'KMX', 'KO', 'KR', 'KVUE', 'L', 'LDOS', 'LEN', 'LH', 'LHX', 'LII', 'LIN', 'LKQ', 'LLY', 'LMT', 'LNT', 'LOW', 'LRCX', 'LULU', 'LUV', 'LVS', 'LW', 'LYB', 'LYV', 'MA', 'MAA', 'MAR', 'MAS', 'MCD', 'MCHP']\n"
     ]
    }
   ],
   "source": [
    "# Define batch size (e.g., 50 tickers per execution)\n",
    "batch_size = 50\n",
    "tickers_to_process = new_tickers[:batch_size]\n",
    "\n",
    "print(f\"Total tickers in Wikipedia table: {len(all_tickers)}\")\n",
    "print(f\"Tickers already processed in raw_prices: {len(processed_tickers)}\")\n",
    "print(f\"New tickers to process in this batch: {len(tickers_to_process)}\")\n",
    "print(\"Tickers in current batch:\", tickers_to_process)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_eod_prices(symbol, start=\"2005-01-01\", end=None, resample_freq=\"daily\"):\n",
    "    \"\"\"\n",
    "    Fetch historical EOD price data for a given symbol from the Tiingo API.\n",
    "    Returns a DataFrame with columns: date, open, high, low, close, volume, \n",
    "    adj_open, adj_high, adj_low, adj_close, adj_volume, div_cash, split_factor, symbol.\n",
    "    \"\"\"\n",
    "    TIINGO_KEY = os.getenv('TIINGO_KEY')\n",
    "    if not TIINGO_KEY:\n",
    "        raise Exception(\"TIINGO_KEY not set in the .env file.\")\n",
    "    \n",
    "    # Convert symbol format for Tiingo API (replace periods with hyphens)\n",
    "    tiingo_symbol = symbol.replace('.', '-')\n",
    "    \n",
    "    base_url = f\"https://api.tiingo.com/tiingo/daily/{tiingo_symbol}/prices\"\n",
    "    params = {\n",
    "        'startDate': start,\n",
    "        'format': 'json',\n",
    "        'token': TIINGO_KEY,\n",
    "        'resampleFreq': resample_freq\n",
    "    }\n",
    "    if end:\n",
    "        params['endDate'] = end\n",
    "    \n",
    "    response = requests.get(base_url, params=params, timeout=30)\n",
    "    response.raise_for_status()\n",
    "    data = response.json()\n",
    "    if not data:\n",
    "        raise Exception(f\"No data returned from Tiingo for symbol: {symbol}\")\n",
    "    \n",
    "    df = pd.DataFrame(data)\n",
    "    \n",
    "    # Define all columns we want to keep, including adjusted prices\n",
    "    columns_to_keep = [\n",
    "        'date', \n",
    "        'open', 'high', 'low', 'close', 'volume',\n",
    "        'adjOpen', 'adjHigh', 'adjLow', 'adjClose', 'adjVolume',\n",
    "        'divCash', 'splitFactor'\n",
    "    ]\n",
    "    \n",
    "    # Keep only columns that exist in the response\n",
    "    df = df[[col for col in columns_to_keep if col in df.columns]]\n",
    "    \n",
    "    # Rename columns to match our database schema\n",
    "    column_mapping = {\n",
    "        'adjOpen': 'adj_open',\n",
    "        'adjHigh': 'adj_high',\n",
    "        'adjLow': 'adj_low',\n",
    "        'adjClose': 'adj_close',\n",
    "        'adjVolume': 'adj_volume',\n",
    "        'divCash': 'div_cash',\n",
    "        'splitFactor': 'split_factor'\n",
    "    }\n",
    "    df = df.rename(columns=column_mapping)\n",
    "    \n",
    "    # Convert date to datetime\n",
    "    df['date'] = pd.to_datetime(df['date'])\n",
    "    \n",
    "    # Convert numeric columns\n",
    "    price_columns = ['open', 'high', 'low', 'close', \n",
    "                    'adj_open', 'adj_high', 'adj_low', 'adj_close',\n",
    "                    'div_cash', 'split_factor']\n",
    "    for col in price_columns:\n",
    "        if col in df.columns:\n",
    "            df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "    \n",
    "    # Convert volume columns\n",
    "    volume_columns = ['volume', 'adj_volume']\n",
    "    for col in volume_columns:\n",
    "        if col in df.columns:\n",
    "            df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "    \n",
    "    # Add symbol column\n",
    "    df['symbol'] = symbol\n",
    "    \n",
    "    # Sort by date and reset index\n",
    "    df = df.sort_values('date').reset_index(drop=True)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing symbol: IT\n",
      "Symbol IT processed successfully.\n",
      "Processing symbol: ITW\n",
      "Symbol ITW processed successfully.\n",
      "Processing symbol: IVZ\n",
      "Symbol IVZ processed successfully.\n",
      "Processing symbol: J\n",
      "Symbol J processed successfully.\n",
      "Processing symbol: JBHT\n",
      "Symbol JBHT processed successfully.\n",
      "Processing symbol: JBL\n",
      "Symbol JBL processed successfully.\n",
      "Processing symbol: JCI\n",
      "Symbol JCI processed successfully.\n",
      "Processing symbol: JKHY\n",
      "Symbol JKHY processed successfully.\n",
      "Processing symbol: JNJ\n",
      "Symbol JNJ processed successfully.\n",
      "Processing symbol: JNPR\n",
      "Symbol JNPR processed successfully.\n",
      "Processing symbol: JPM\n",
      "Symbol JPM processed successfully.\n",
      "Processing symbol: K\n",
      "Symbol K processed successfully.\n",
      "Processing symbol: KDP\n",
      "Symbol KDP processed successfully.\n",
      "Processing symbol: KEY\n",
      "Symbol KEY processed successfully.\n",
      "Processing symbol: KEYS\n",
      "Symbol KEYS processed successfully.\n",
      "Processing symbol: KHC\n",
      "Symbol KHC processed successfully.\n",
      "Processing symbol: KIM\n",
      "Symbol KIM processed successfully.\n",
      "Processing symbol: KKR\n",
      "Symbol KKR processed successfully.\n",
      "Processing symbol: KLAC\n",
      "Symbol KLAC processed successfully.\n",
      "Processing symbol: KMB\n",
      "Symbol KMB processed successfully.\n",
      "Processing symbol: KMI\n",
      "Symbol KMI processed successfully.\n",
      "Processing symbol: KMX\n",
      "Symbol KMX processed successfully.\n",
      "Processing symbol: KO\n",
      "Symbol KO processed successfully.\n",
      "Processing symbol: KR\n",
      "Symbol KR processed successfully.\n",
      "Processing symbol: KVUE\n",
      "Symbol KVUE processed successfully.\n",
      "Processing symbol: L\n",
      "Symbol L processed successfully.\n",
      "Processing symbol: LDOS\n",
      "Symbol LDOS processed successfully.\n",
      "Processing symbol: LEN\n",
      "Symbol LEN processed successfully.\n",
      "Processing symbol: LH\n",
      "Symbol LH processed successfully.\n",
      "Processing symbol: LHX\n",
      "Symbol LHX processed successfully.\n",
      "Processing symbol: LII\n",
      "Symbol LII processed successfully.\n",
      "Processing symbol: LIN\n",
      "Symbol LIN processed successfully.\n",
      "Processing symbol: LKQ\n",
      "Symbol LKQ processed successfully.\n",
      "Processing symbol: LLY\n",
      "Symbol LLY processed successfully.\n",
      "Processing symbol: LMT\n",
      "Symbol LMT processed successfully.\n",
      "Processing symbol: LNT\n",
      "Symbol LNT processed successfully.\n",
      "Processing symbol: LOW\n",
      "Symbol LOW processed successfully.\n",
      "Processing symbol: LRCX\n",
      "Symbol LRCX processed successfully.\n",
      "Processing symbol: LULU\n",
      "Symbol LULU processed successfully.\n",
      "Processing symbol: LUV\n",
      "Symbol LUV processed successfully.\n",
      "Processing symbol: LVS\n",
      "Symbol LVS processed successfully.\n",
      "Processing symbol: LW\n",
      "Symbol LW processed successfully.\n",
      "Processing symbol: LYB\n",
      "Symbol LYB processed successfully.\n",
      "Processing symbol: LYV\n",
      "Symbol LYV processed successfully.\n",
      "Processing symbol: MA\n",
      "Symbol MA processed successfully.\n",
      "Processing symbol: MAA\n",
      "Symbol MAA processed successfully.\n",
      "Processing symbol: MAR\n",
      "Symbol MAR processed successfully.\n",
      "Processing symbol: MAS\n",
      "Symbol MAS processed successfully.\n",
      "Processing symbol: MCD\n",
      "Symbol MCD processed successfully.\n",
      "Processing symbol: MCHP\n",
      "Symbol MCHP processed successfully.\n",
      "Batch processing complete. Run this cell again after one hour for the next batch.\n"
     ]
    }
   ],
   "source": [
    "for symbol in tickers_to_process:\n",
    "    try:\n",
    "        print(f\"Processing symbol: {symbol}\")\n",
    "        df_symbol = get_eod_prices(symbol)\n",
    "        # Wrap the insertion in a transaction so that each is rolled back if an error occurs.\n",
    "        with engine.begin() as connection:\n",
    "            df_symbol.to_sql(name=\"raw_prices\", con=connection, if_exists=\"append\", index=False)\n",
    "        print(f\"Symbol {symbol} processed successfully.\")\n",
    "    except IntegrityError as ie:\n",
    "        # Duplicate entry (error code 1062) likely means data for those dates already exists.\n",
    "        if \"Duplicate entry\" in str(ie):\n",
    "            print(f\"Duplicate entry error for {symbol}. Skipping insertion.\")\n",
    "        else:\n",
    "            print(f\"IntegrityError processing symbol {symbol}: {ie}\")\n",
    "    except OperationalError as oe:\n",
    "        print(f\"OperationalError processing symbol {symbol}: {oe}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing symbol {symbol}: {e}\")\n",
    "    time.sleep(1)  # Delay between requests\n",
    "\n",
    "print(\"Batch processing complete. Run this cell again after one hour for the next batch.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
